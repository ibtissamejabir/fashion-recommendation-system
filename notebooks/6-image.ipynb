{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ba37a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:30.407389Z",
     "iopub.status.busy": "2026-02-19T10:12:30.407172Z",
     "iopub.status.idle": "2026-02-19T10:12:47.081788Z",
     "shell.execute_reply": "2026-02-19T10:12:47.081022Z"
    },
    "papermill": {
     "duration": 16.680152,
     "end_time": "2026-02-19T10:12:47.083383",
     "exception": false,
     "start_time": "2026-02-19T10:12:30.403231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 214MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet50 and remove final classification layer\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet.fc = torch.nn.Identity()\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "print(\"Model ready on:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbec770c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:47.090695Z",
     "iopub.status.busy": "2026-02-19T10:12:47.090031Z",
     "iopub.status.idle": "2026-02-19T10:12:47.093897Z",
     "shell.execute_reply": "2026-02-19T10:12:47.093307Z"
    },
    "papermill": {
     "duration": 0.008793,
     "end_time": "2026-02-19T10:12:47.095218",
     "exception": false,
     "start_time": "2026-02-19T10:12:47.086425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_path(article_id):\n",
    "    article_str = str(article_id).zfill(10)\n",
    "    folder = article_str[:3]\n",
    "    return f\"/kaggle/input/competitions/h-and-m-personalized-fashion-recommendations/images/{folder}/{article_str}.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff152752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:47.101349Z",
     "iopub.status.busy": "2026-02-19T10:12:47.100967Z",
     "iopub.status.idle": "2026-02-19T10:12:47.105902Z",
     "shell.execute_reply": "2026-02-19T10:12:47.105321Z"
    },
    "papermill": {
     "duration": 0.00943,
     "end_time": "2026-02-19T10:12:47.107184",
     "exception": false,
     "start_time": "2026-02-19T10:12:47.097754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, image_ids, image_folder, transform):\n",
    "        self.image_ids = image_ids\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.image_folder, f\"{article_id}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa842a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:47.113211Z",
     "iopub.status.busy": "2026-02-19T10:12:47.112759Z",
     "iopub.status.idle": "2026-02-19T10:12:48.030812Z",
     "shell.execute_reply": "2026-02-19T10:12:48.029947Z"
    },
    "papermill": {
     "duration": 0.92262,
     "end_time": "2026-02-19T10:12:48.032281",
     "exception": false,
     "start_time": "2026-02-19T10:12:47.109661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles shape: (105542, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "articles = pd.read_csv(\n",
    "    \"/kaggle/input/competitions/h-and-m-personalized-fashion-recommendations/articles.csv\"\n",
    ")\n",
    "\n",
    "print(\"Articles shape:\", articles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a5d8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:48.038852Z",
     "iopub.status.busy": "2026-02-19T10:12:48.038586Z",
     "iopub.status.idle": "2026-02-19T10:12:48.042229Z",
     "shell.execute_reply": "2026-02-19T10:12:48.041689Z"
    },
    "papermill": {
     "duration": 0.008446,
     "end_time": "2026-02-19T10:12:48.043506",
     "exception": false,
     "start_time": "2026-02-19T10:12:48.035060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_path(article_id):\n",
    "    article_str = str(article_id).zfill(10)\n",
    "    folder = article_str[:3]\n",
    "    return f\"/kaggle/input/competitions/h-and-m-personalized-fashion-recommendations/images/{folder}/{article_str}.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb8c96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:48.049604Z",
     "iopub.status.busy": "2026-02-19T10:12:48.049361Z",
     "iopub.status.idle": "2026-02-19T10:12:48.053183Z",
     "shell.execute_reply": "2026-02-19T10:12:48.052612Z"
    },
    "papermill": {
     "duration": 0.008333,
     "end_time": "2026-02-19T10:12:48.054395",
     "exception": false,
     "start_time": "2026-02-19T10:12:48.046062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d21882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:48.060425Z",
     "iopub.status.busy": "2026-02-19T10:12:48.060209Z",
     "iopub.status.idle": "2026-02-19T10:12:48.065313Z",
     "shell.execute_reply": "2026-02-19T10:12:48.064783Z"
    },
    "papermill": {
     "duration": 0.009634,
     "end_time": "2026-02-19T10:12:48.066619",
     "exception": false,
     "start_time": "2026-02-19T10:12:48.056985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, article_ids, transform):\n",
    "        self.article_ids = article_ids\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.article_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article_id = self.article_ids[idx]\n",
    "        # Build image path\n",
    "        article_str = str(article_id).zfill(10)\n",
    "        folder = article_str[:3]\n",
    "        img_path = f\"/kaggle/input/competitions/h-and-m-personalized-fashion-recommendations/images/{folder}/{article_str}.jpg\"\n",
    "        \n",
    "        # Skip missing images\n",
    "        if not os.path.exists(img_path):\n",
    "            # Return None, the DataLoader collate_fn will skip it\n",
    "            return None\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, article_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d3dd97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:48.072967Z",
     "iopub.status.busy": "2026-02-19T10:12:48.072731Z",
     "iopub.status.idle": "2026-02-19T10:12:48.076721Z",
     "shell.execute_reply": "2026-02-19T10:12:48.076064Z"
    },
    "papermill": {
     "duration": 0.008839,
     "end_time": "2026-02-19T10:12:48.078064",
     "exception": false,
     "start_time": "2026-02-19T10:12:48.069225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    images, ids = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0951d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:12:48.084152Z",
     "iopub.status.busy": "2026-02-19T10:12:48.083931Z",
     "iopub.status.idle": "2026-02-19T10:18:28.859370Z",
     "shell.execute_reply": "2026-02-19T10:18:28.858619Z"
    },
    "papermill": {
     "duration": 340.78325,
     "end_time": "2026-02-19T10:18:28.863983",
     "exception": false,
     "start_time": "2026-02-19T10:12:48.080733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 105542\n",
      "Articles with images: 105100\n"
     ]
    }
   ],
   "source": [
    "# Correct order: first define valid_article_ids\n",
    "article_ids = articles[\"article_id\"].unique().tolist()\n",
    "valid_article_ids = [aid for aid in article_ids if os.path.exists(get_image_path(aid))]\n",
    "print(f\"Total articles: {len(article_ids)}\")\n",
    "print(f\"Articles with images: {len(valid_article_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a0c1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:18:28.870979Z",
     "iopub.status.busy": "2026-02-19T10:18:28.870718Z",
     "iopub.status.idle": "2026-02-19T10:18:28.875234Z",
     "shell.execute_reply": "2026-02-19T10:18:28.874416Z"
    },
    "papermill": {
     "duration": 0.009765,
     "end_time": "2026-02-19T10:18:28.876588",
     "exception": false,
     "start_time": "2026-02-19T10:18:28.866823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader using only articles with images\n",
    "dataset = FashionDataset(valid_article_ids, transform)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c83c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:18:28.883594Z",
     "iopub.status.busy": "2026-02-19T10:18:28.882987Z",
     "iopub.status.idle": "2026-02-19T10:51:03.744145Z",
     "shell.execute_reply": "2026-02-19T10:51:03.743131Z"
    },
    "papermill": {
     "duration": 1954.866608,
     "end_time": "2026-02-19T10:51:03.746027",
     "exception": false,
     "start_time": "2026-02-19T10:18:28.879419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1643/1643 [32:34<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.eval()\n",
    "resnet.to(device)\n",
    "\n",
    "item_embeddings = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        if batch is None:\n",
    "            continue\n",
    "        images, ids = batch\n",
    "        images = images.to(device)\n",
    "        embeddings = resnet(images).cpu().numpy()\n",
    "        for i, article_id in enumerate(ids):\n",
    "            item_embeddings[int(article_id)] = embeddings[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3277f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:51:03.879520Z",
     "iopub.status.busy": "2026-02-19T10:51:03.879189Z",
     "iopub.status.idle": "2026-02-19T10:51:05.591327Z",
     "shell.execute_reply": "2026-02-19T10:51:05.590589Z"
    },
    "papermill": {
     "duration": 1.781684,
     "end_time": "2026-02-19T10:51:05.592848",
     "exception": false,
     "start_time": "2026-02-19T10:51:03.811164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/kaggle/working/image_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_embeddings, f)\n",
    "\n",
    "print(\"Saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5bbb34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:51:05.719597Z",
     "iopub.status.busy": "2026-02-19T10:51:05.719001Z",
     "iopub.status.idle": "2026-02-19T10:51:08.936737Z",
     "shell.execute_reply": "2026-02-19T10:51:08.936078Z"
    },
    "papermill": {
     "duration": 3.281968,
     "end_time": "2026-02-19T10:51:08.938613",
     "exception": false,
     "start_time": "2026-02-19T10:51:05.656645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "all_items = list(item_embeddings.keys())\n",
    "all_vectors = np.array([item_embeddings[i] for i in all_items])\n",
    "\n",
    "def recommend_similar_items(query_item_id, top_k=12):\n",
    "    \n",
    "    if query_item_id not in item_embeddings:\n",
    "        return []\n",
    "    \n",
    "    query_vector = item_embeddings[query_item_id].reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_vector, all_vectors)[0]\n",
    "    \n",
    "    top_indices = similarities.argsort()[-top_k-1:][::-1]\n",
    "    \n",
    "    recommended = [\n",
    "        all_items[i]\n",
    "        for i in top_indices\n",
    "        if all_items[i] != query_item_id\n",
    "    ]\n",
    "    \n",
    "    return recommended[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e047d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T10:51:09.065035Z",
     "iopub.status.busy": "2026-02-19T10:51:09.064360Z",
     "iopub.status.idle": "2026-02-19T10:51:10.347351Z",
     "shell.execute_reply": "2026-02-19T10:51:10.345356Z"
    },
    "papermill": {
     "duration": 1.347396,
     "end_time": "2026-02-19T10:51:10.349421",
     "exception": false,
     "start_time": "2026-02-19T10:51:09.002025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[626366003,\n",
       " 626366002,\n",
       " 767834001,\n",
       " 717464001,\n",
       " 733814001,\n",
       " 572799008,\n",
       " 824999001,\n",
       " 538699001,\n",
       " 647522002,\n",
       " 800869001,\n",
       " 868680001,\n",
       " 651465001]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_similar_items(article_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f659e1b",
   "metadata": {
    "papermill": {
     "duration": 0.06395,
     "end_time": "2026-02-19T10:51:10.518787",
     "exception": false,
     "start_time": "2026-02-19T10:51:10.454837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phase 6 — Image-Based Recommendation\n",
    "\n",
    "In this phase, we build a **visual recommender system** for fashion items using product images.  \n",
    "The main goals are:\n",
    "\n",
    "- Extract **image embeddings** using a pretrained CNN (ResNet50).  \n",
    "- Store **item-level visual vectors** for all products.  \n",
    "- Recommend **visually similar items** based on cosine similarity.  \n",
    "- Prepare for the **Hybrid Recommender System** (Phase 7).\n",
    "\n",
    "---\n",
    "\n",
    "##  GPU Setup\n",
    "\n",
    "For efficient computation, we use Kaggle GPU:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3103714,
     "sourceId": 31254,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 15378835,
     "datasetId": 9292063,
     "sourceId": 14548355,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2326.594137,
   "end_time": "2026-02-19T10:51:13.512494",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-19T10:12:26.918357",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
